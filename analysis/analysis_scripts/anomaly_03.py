#!/usr/bin/env python3
"""
Django ê¸°ë°˜ ì´ìƒ í–‰ìœ„ ë¶„ì„ê¸°
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from django.apps import apps

plt.rcParams['font.family'] = 'DejaVu Sans'
sns.set_style("whitegrid")


class AnomalyAnalyzer:
    def __init__(self):
        # Django ORM ì‚¬ìš©
        LogEntry = apps.get_model('logs', 'LogEntry')
        self.LogEntry = LogEntry
        self.df = None
        self._load_data()

        self.thresholds = {
            'volume_zscore_threshold': 2.0,
            'behavior_contamination': 0.1,
            'time_window_hours': 1
        }

    def _load_data(self):
        """Django ORMìœ¼ë¡œ ë°ì´í„° ë¡œë“œ"""
        entries = self.LogEntry.objects.all().values(
            'timestamp', 'log_type', 'source_ip', 'message', 'severity', 'metadata'
        )
        self.df = pd.DataFrame(entries)

        if len(self.df) > 0:
            self.df['timestamp'] = pd.to_datetime(self.df['timestamp'], errors='coerce')
            self.df = self.df.dropna(subset=['timestamp'])
            self.df['hour'] = self.df['timestamp'].dt.hour

    def get_anomaly_overview_text(self) -> str:
        """ì´ìƒ í–‰ìœ„ ë¶„ì„ ê°œìš”"""
        if len(self.df) == 0:
            return "ğŸ” ë¶„ì„í•  ì´ìƒ í–‰ìœ„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        total_logs = len(self.df)
        unique_ips = self.df['source_ip'].dropna().nunique()
        time_span = (self.df['timestamp'].max() - self.df['timestamp'].min()).days

        # ê¸°ë³¸ ì´ìƒ íƒì§€
        volume_anomalies, _ = self.detect_volume_anomalies()
        behavioral_anomalies, _ = self.detect_behavioral_anomalies()
        time_anomalies, _ = self.detect_time_anomalies()

        overview = f"""
ğŸ” ì´ìƒ í–‰ìœ„ ë¶„ì„ (Django ORM)
{'=' * 30}
â€¢ ì´ ë¡œê·¸ ìˆ˜: {total_logs:,}ê°œ
â€¢ ë¶„ì„ IP ìˆ˜: {unique_ips}ê°œ
â€¢ ë¶„ì„ ê¸°ê°„: {time_span}ì¼
â€¢ ë³¼ë¥¨ ì´ìƒ: {len(volume_anomalies)}ê±´
â€¢ í–‰ìœ„ ì´ìƒ: {len(behavioral_anomalies)}ê±´
â€¢ ì‹œê°„ ì´ìƒ: {len(time_anomalies)}ê±´
"""
        return overview

    def detect_volume_anomalies(self) -> Tuple[List[Dict], str]:
        """ë³¼ë¥¨ ê¸°ë°˜ ì´ìƒ íƒì§€"""
        if len(self.df) == 0:
            return [], "ë³¼ë¥¨ ì´ìƒ íƒì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        # ì‹œê°„ë³„ ë³¼ë¥¨ ë¶„ì„
        hourly_volumes = self.df.groupby('hour').size()
        volume_mean = hourly_volumes.mean()
        volume_std = hourly_volumes.std()

        anomalies = []
        for hour, count in hourly_volumes.items():
            z_score = abs((count - volume_mean) / volume_std) if volume_std > 0 else 0

            if z_score > self.thresholds['volume_zscore_threshold']:
                anomalies.append({
                    'hour': hour,
                    'volume': count,
                    'z_score': z_score,
                    'type': 'high_volume' if count > volume_mean else 'low_volume'
                })

        # IPë³„ ë³¼ë¥¨ ì´ìƒ
        ip_volumes = self.df['source_ip'].value_counts()
        ip_mean = ip_volumes.mean()
        ip_std = ip_volumes.std()

        for ip, count in ip_volumes.head(20).items():
            z_score = abs((count - ip_mean) / ip_std) if ip_std > 0 else 0

            if z_score > self.thresholds['volume_zscore_threshold']:
                anomalies.append({
                    'source_ip': ip,
                    'volume': count,
                    'z_score': z_score,
                    'type': 'high_volume_ip'
                })

        summary = f"""
ğŸ“Š ë³¼ë¥¨ ì´ìƒ íƒì§€
{'=' * 30}
â€¢ íƒì§€ëœ ì´ìƒ: {len(anomalies)}ê±´
â€¢ ì‹œê°„ë³„ í‰ê· : {volume_mean:.1f}ê°œ
â€¢ IPë³„ í‰ê· : {ip_mean:.1f}ê°œ
"""
        return anomalies, summary

    def detect_behavioral_anomalies(self) -> Tuple[List[Dict], str]:
        """í–‰ìœ„ íŒ¨í„´ ê¸°ë°˜ ì´ìƒ íƒì§€"""
        if len(self.df) == 0:
            return [], "í–‰ìœ„ ì´ìƒ íƒì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        anomalies = []

        # IPë³„ í–‰ìœ„ íŒ¨í„´ ë¶„ì„
        for ip in self.df['source_ip'].dropna().unique():
            ip_data = self.df[self.df['source_ip'] == ip]

            if len(ip_data) < 5:  # ìµœì†Œ ë°ì´í„° ìš”êµ¬
                continue

            # íŠ¹ì„± ë²¡í„° ìƒì„±
            features = []

            # ë¡œê·¸ íƒ€ì… ë‹¤ì–‘ì„±
            log_type_diversity = len(ip_data['log_type'].unique())
            features.append(log_type_diversity)

            # ì‹¬ê°ë„ ë¶„í¬
            high_severity_ratio = len(ip_data[ip_data['severity'] == 'high']) / len(ip_data)
            features.append(high_severity_ratio)

            # ì‹œê°„ íŒ¨í„´ (í™œë™ ì‹œê°„ëŒ€ ìˆ˜)
            active_hours = len(ip_data['hour'].unique())
            features.append(active_hours)

            # ìš”ì²­ ê°„ê²© ë¶„ì„
            if len(ip_data) > 1:
                time_diffs = ip_data['timestamp'].diff().dt.total_seconds()
                avg_interval = time_diffs.mean()
                features.append(avg_interval if not pd.isna(avg_interval) else 0)
            else:
                features.append(0)

            # ì´ìƒ ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
            anomaly_score = 0

            # ë‹¤ì–‘í•œ ë¡œê·¸ íƒ€ì… ì ‘ê·¼ (5ê°œ ì´ìƒì´ë©´ ì˜ì‹¬)
            if log_type_diversity >= 5:
                anomaly_score += 2

            # ë†’ì€ ì‹¬ê°ë„ ë¹„ìœ¨ (50% ì´ìƒì´ë©´ ì˜ì‹¬)
            if high_severity_ratio >= 0.5:
                anomaly_score += 3

            # 24ì‹œê°„ ë‚´ë‚´ í™œë™ (ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒ¨í„´)
            if active_hours >= 20:
                anomaly_score += 2

            # ë„ˆë¬´ ë¹ ë¥¸ ìš”ì²­ ê°„ê²© (10ì´ˆ ì´í•˜)
            if len(ip_data) > 1 and avg_interval < 10:
                anomaly_score += 2

            if anomaly_score >= 3:  # ì„ê³„ê°’
                anomalies.append({
                    'source_ip': ip,
                    'anomaly_score': anomaly_score,
                    'log_type_diversity': log_type_diversity,
                    'high_severity_ratio': high_severity_ratio,
                    'active_hours': active_hours,
                    'request_count': len(ip_data),
                    'avg_interval': avg_interval if len(ip_data) > 1 else 0
                })

        # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        anomalies.sort(key=lambda x: x['anomaly_score'], reverse=True)

        summary = f"""
ğŸ¤– í–‰ìœ„ ì´ìƒ íƒì§€
{'=' * 30}
â€¢ íƒì§€ëœ ì´ìƒ: {len(anomalies)}ê±´
â€¢ ë¶„ì„ IP ìˆ˜: {self.df['source_ip'].nunique()}ê°œ
â€¢ íƒì§€ ê¸°ì¤€: ë‹¤ì–‘ì„±, ì‹¬ê°ë„, ì‹œê°„íŒ¨í„´
"""
        return anomalies, summary

    def detect_time_anomalies(self) -> Tuple[List[Dict], str]:
        """ì‹œê°„ íŒ¨í„´ ê¸°ë°˜ ì´ìƒ íƒì§€"""
        if len(self.df) == 0:
            return [], "ì‹œê°„ ì´ìƒ íƒì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        anomalies = []

        # ë¹„ì •ìƒì ì¸ ì‹œê°„ëŒ€ í™œë™ íƒì§€
        hourly_activity = self.df.groupby('hour').size()

        # ìƒˆë²½ ì‹œê°„ëŒ€ (0-5ì‹œ) ê³ í™œë™ íƒì§€
        night_hours = [0, 1, 2, 3, 4, 5]
        night_activity = sum(hourly_activity.get(hour, 0) for hour in night_hours)
        total_activity = hourly_activity.sum()
        night_ratio = night_activity / total_activity if total_activity > 0 else 0

        if night_ratio > 0.3:  # 30% ì´ìƒì´ë©´ ì´ìƒ
            anomalies.append({
                'type': 'night_activity',
                'ratio': night_ratio,
                'night_logs': night_activity,
                'description': 'ìƒˆë²½ ì‹œê°„ëŒ€ ê³¼ë‹¤ í™œë™'
            })

        # IPë³„ ì‹œê°„ íŒ¨í„´ ë¶„ì„
        for ip in self.df['source_ip'].dropna().unique():
            ip_data = self.df[self.df['source_ip'] == ip]

            if len(ip_data) < 10:  # ìµœì†Œ ë°ì´í„° ìš”êµ¬
                continue

            ip_hours = ip_data['hour'].unique()

            # 24ì‹œê°„ ë‚´ë‚´ í™œë™í•˜ëŠ” IP
            if len(ip_hours) >= 20:
                anomalies.append({
                    'type': 'continuous_activity',
                    'source_ip': ip,
                    'active_hours': len(ip_hours),
                    'request_count': len(ip_data),
                    'description': 'ì§€ì†ì  í™œë™ íŒ¨í„´'
                })

            # íŠ¹ì • ì‹œê°„ëŒ€ ì§‘ì¤‘ í™œë™
            hour_counts = ip_data['hour'].value_counts()
            max_hour_count = hour_counts.max()
            max_hour_ratio = max_hour_count / len(ip_data)

            if max_hour_ratio > 0.8 and len(ip_data) > 20:  # 80% ì´ìƒ íŠ¹ì • ì‹œê°„ëŒ€
                peak_hour = hour_counts.idxmax()
                anomalies.append({
                    'type': 'concentrated_activity',
                    'source_ip': ip,
                    'peak_hour': peak_hour,
                    'concentration_ratio': max_hour_ratio,
                    'request_count': len(ip_data),
                    'description': f'{peak_hour}ì‹œ ì§‘ì¤‘ í™œë™'
                })

        summary = f"""
â° ì‹œê°„ ì´ìƒ íƒì§€
{'=' * 30}
â€¢ íƒì§€ëœ ì´ìƒ: {len(anomalies)}ê±´
â€¢ ìƒˆë²½ í™œë™ ë¹„ìœ¨: {night_ratio:.1%}
â€¢ ë¶„ì„ ê¸°ê°„: {self.df['timestamp'].dt.date.nunique()}ì¼
"""
        return anomalies, summary

    def plot_anomaly_detection(self, save_path: Optional[str] = None):
        """ì´ìƒ íƒì§€ ì‹œê°í™”"""
        if len(self.df) == 0:
            print("ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        fig, axes = plt.subplots(2, 2, figsize=(15, 10))

        # 1. ì‹œê°„ë³„ ë³¼ë¥¨ê³¼ ì´ìƒì  í‘œì‹œ
        hourly_volumes = self.df.groupby('hour').size()
        volume_mean = hourly_volumes.mean()
        volume_std = hourly_volumes.std()

        axes[0, 0].bar(hourly_volumes.index, hourly_volumes.values, alpha=0.7)
        axes[0, 0].axhline(y=volume_mean + 2 * volume_std, color='red', linestyle='--',
                           label='ì´ìƒ ì„ê³„ê°’')
        axes[0, 0].axhline(y=volume_mean, color='green', linestyle='-', label='í‰ê· ')
        axes[0, 0].set_title('ì‹œê°„ë³„ ë¡œê·¸ ë³¼ë¥¨ ë° ì´ìƒì ', fontweight='bold')
        axes[0, 0].set_xlabel('ì‹œê°„')
        axes[0, 0].set_ylabel('ë¡œê·¸ ìˆ˜')
        axes[0, 0].legend()

        # 2. IPë³„ ìš”ì²­ ìˆ˜ ë¶„í¬
        ip_counts = self.df['source_ip'].value_counts().head(20)
        axes[0, 1].barh(range(len(ip_counts)), ip_counts.values)
        axes[0, 1].set_yticks(range(len(ip_counts)))
        axes[0, 1].set_yticklabels(ip_counts.index)
        axes[0, 1].set_title('ìƒìœ„ 20ê°œ IP ìš”ì²­ ìˆ˜', fontweight='bold')
        axes[0, 1].set_xlabel('ìš”ì²­ ìˆ˜')

        # 3. ì‹¬ê°ë„ë³„ ì‹œê°„ ë¶„í¬
        severity_time = self.df.groupby(['hour', 'severity']).size().unstack(fill_value=0)
        severity_time.plot(kind='area', stacked=True, ax=axes[1, 0], alpha=0.7)
        axes[1, 0].set_title('ì‹œê°„ë³„ ì‹¬ê°ë„ ë¶„í¬', fontweight='bold')
        axes[1, 0].set_xlabel('ì‹œê°„')
        axes[1, 0].set_ylabel('ë¡œê·¸ ìˆ˜')
        axes[1, 0].legend(title='ì‹¬ê°ë„', loc='upper right')

        # 4. ì´ìƒ ì ìˆ˜ ë¶„í¬
        behavioral_anomalies, _ = self.detect_behavioral_anomalies()
        if behavioral_anomalies:
            anomaly_scores = [a['anomaly_score'] for a in behavioral_anomalies]
            axes[1, 1].hist(anomaly_scores, bins=10, alpha=0.7, color='orange')
            axes[1, 1].set_title('í–‰ìœ„ ì´ìƒ ì ìˆ˜ ë¶„í¬', fontweight='bold')
            axes[1, 1].set_xlabel('ì´ìƒ ì ìˆ˜')
            axes[1, 1].set_ylabel('IP ìˆ˜')
        else:
            axes[1, 1].text(0.5, 0.5, 'í–‰ìœ„ ì´ìƒ ì—†ìŒ', transform=axes[1, 1].transAxes,
                            ha='center', va='center')
            axes[1, 1].set_title('í–‰ìœ„ ì´ìƒ ì ìˆ˜ ë¶„í¬', fontweight='bold')

        plt.tight_layout()
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()

    def generate_anomaly_report(self) -> str:
        """ì´ìƒ í–‰ìœ„ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        volume_anomalies, volume_summary = self.detect_volume_anomalies()
        behavioral_anomalies, behavioral_summary = self.detect_behavioral_anomalies()
        time_anomalies, time_summary = self.detect_time_anomalies()

        report = f"""
{'=' * 60}
ğŸ” ì´ìƒ í–‰ìœ„ ë¶„ì„ ë¦¬í¬íŠ¸ (Django ORM)
{'=' * 60}

{self.get_anomaly_overview_text()}

{'=' * 60}
{volume_summary}
{'=' * 60}
"""

        if volume_anomalies:
            report += "ìƒì„¸ ë³¼ë¥¨ ì´ìƒ:\n"
            for anomaly in volume_anomalies[:10]:
                if 'hour' in anomaly:
                    report += f"â€¢ {anomaly['hour']}ì‹œ: {anomaly['volume']}ê°œ (Z-ì ìˆ˜: {anomaly['z_score']:.2f})\n"
                elif 'source_ip' in anomaly:
                    report += f"â€¢ IP {anomaly['source_ip']}: {anomaly['volume']}ê°œ (Z-ì ìˆ˜: {anomaly['z_score']:.2f})\n"

        report += f"""

{'=' * 60}
{behavioral_summary}
{'=' * 60}
"""

        for i, anomaly in enumerate(behavioral_anomalies[:10], 1):
            report += f"\n{i}. {anomaly['source_ip']}\n"
            report += f"   â€¢ ì´ìƒ ì ìˆ˜: {anomaly['anomaly_score']}\n"
            report += f"   â€¢ ë¡œê·¸ íƒ€ì…: {anomaly['log_type_diversity']}ê°œ\n"
            report += f"   â€¢ ê³ ìœ„í—˜ ë¹„ìœ¨: {anomaly['high_severity_ratio']:.1%}\n"
            report += f"   â€¢ í™œë™ ì‹œê°„: {anomaly['active_hours']}ì‹œê°„ëŒ€\n"

        report += f"""

{'=' * 60}
{time_summary}
{'=' * 60}
"""

        for anomaly in time_anomalies:
            if anomaly['type'] == 'night_activity':
                report += f"â€¢ ìƒˆë²½ í™œë™ ë¹„ìœ¨: {anomaly['ratio']:.1%}\n"
            elif anomaly['type'] == 'continuous_activity':
                report += f"â€¢ ì§€ì† í™œë™ IP: {anomaly['source_ip']} ({anomaly['active_hours']}ì‹œê°„ëŒ€)\n"
            elif anomaly['type'] == 'concentrated_activity':
                report += f"â€¢ ì§‘ì¤‘ í™œë™ IP: {anomaly['source_ip']} ({anomaly['peak_hour']}ì‹œ ì§‘ì¤‘)\n"

        report += f"""

{'=' * 60}
ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Django ORM ê¸°ë°˜ ì´ìƒ íƒì§€
"""
        return report