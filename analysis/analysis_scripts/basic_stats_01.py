#!/usr/bin/env python3
"""
Django ê¸°ë°˜ ê¸°ë³¸ í†µê³„ ë¶„ì„ê¸°
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import json
from datetime import datetime
from collections import Counter
from typing import Dict, List, Optional
from django.apps import apps

plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")


class BasicStatsAnalyzer:
    def __init__(self):
        # Django ORM ì‚¬ìš©
        LogEntry = apps.get_model('logs', 'LogEntry')
        self.LogEntry = LogEntry
        self.df = None
        self._load_data()

    def _load_data(self):
        """Django ORMìœ¼ë¡œ ë°ì´í„° ë¡œë“œ"""
        entries = self.LogEntry.objects.all().values(
            'timestamp', 'log_type', 'source_ip', 'message', 'severity', 'metadata'
        )
        self.df = pd.DataFrame(entries)

        if len(self.df) > 0:
            self.df['timestamp'] = pd.to_datetime(self.df['timestamp'], errors='coerce')
            self.df = self.df.dropna(subset=['timestamp'])
            self.df['hour'] = self.df['timestamp'].dt.hour
            self.df['date'] = self.df['timestamp'].dt.date

    def get_metadata_field(self, field_name):
        """ë©”íƒ€ë°ì´í„°ì—ì„œ í•„ë“œ ì¶”ì¶œ"""

        def extract_field(metadata_str):
            try:
                if pd.isna(metadata_str):
                    return None
                metadata = json.loads(metadata_str)
                return metadata.get(field_name)
            except:
                return None

        return self.df['metadata'].apply(extract_field)

    def get_overview_text(self) -> str:
        """ì „ì²´ ê°œìš”"""
        if len(self.df) == 0:
            return "ğŸ“Š ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        total_logs = len(self.df)
        unique_ips = self.df['source_ip'].dropna().nunique()
        log_types = self.df['log_type'].nunique()
        severity_dist = self.df['severity'].value_counts()

        overview = f"""
ğŸ“Š ê¸°ë³¸ í†µê³„ ë¶„ì„ (Django ORM)
{'=' * 30}
â€¢ ì´ ë¡œê·¸ ìˆ˜: {total_logs:,}ê°œ
â€¢ ê³ ìœ  IP ìˆ˜: {unique_ips}ê°œ
â€¢ ë¡œê·¸ íƒ€ì…: {log_types}ê°œ
â€¢ ì‹¬ê°ë„ë³„ ë¶„í¬:
"""
        for severity, count in severity_dist.items():
            percentage = (count / total_logs) * 100
            overview += f"  - {severity}: {count:,}ê°œ ({percentage:.1f}%)\n"

        # ì‹œê°„ëŒ€ë³„ ë¶„ì„
        if 'hour' in self.df.columns:
            peak_hour = self.df['hour'].value_counts().index[0]
            overview += f"\nâ€¢ ìµœë‹¤ í™œë™ ì‹œê°„: {peak_hour}ì‹œ"

        return overview

    def get_time_analysis_text(self) -> str:
        """ì‹œê°„ëŒ€ë³„ ë¶„ì„"""
        if len(self.df) == 0:
            return "ì‹œê°„ëŒ€ë³„ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        hourly_counts = self.df['hour'].value_counts().sort_index()
        peak_hour = hourly_counts.index[0]
        peak_count = hourly_counts.iloc[0]

        # ì¼ë³„ íŠ¸ë Œë“œ
        daily_counts = self.df.groupby('date').size()
        avg_daily = daily_counts.mean()

        analysis = f"""
â° ì‹œê°„ëŒ€ë³„ ë¶„ì„
{'=' * 30}
â€¢ ìµœë‹¤ í™œë™ ì‹œê°„: {peak_hour}ì‹œ ({peak_count}ê°œ)
â€¢ ì¼í‰ê·  ë¡œê·¸: {avg_daily:.1f}ê°œ
â€¢ ë¶„ì„ ê¸°ê°„: {daily_counts.index.min()} ~ {daily_counts.index.max()}
"""

        # ì‹œê°„ëŒ€ë³„ ìƒìœ„ 3ê°œ
        analysis += "\nâ€¢ í™œë™ëŸ‰ ìƒìœ„ 3ì‹œê°„:\n"
        for hour, count in hourly_counts.head(3).items():
            analysis += f"  - {hour}ì‹œ: {count}ê°œ\n"

        return analysis

    def analyze_log_types(self) -> Dict:
        """ë¡œê·¸ íƒ€ì…ë³„ ë¶„ì„"""
        if len(self.df) == 0:
            return {}

        type_analysis = {}
        for log_type in self.df['log_type'].unique():
            type_data = self.df[self.df['log_type'] == log_type]

            type_analysis[log_type] = {
                'count': len(type_data),
                'percentage': len(type_data) / len(self.df) * 100,
                'severity_dist': type_data['severity'].value_counts().to_dict(),
                'unique_ips': type_data['source_ip'].nunique(),
                'peak_hour': type_data['hour'].value_counts().index[0] if len(type_data) > 0 else None
            }

        return type_analysis

    def analyze_source_ips(self) -> Dict:
        """IPë³„ ë¶„ì„"""
        if len(self.df) == 0:
            return {}

        ip_stats = {}
        ip_counts = self.df['source_ip'].value_counts()

        for ip, count in ip_counts.head(10).items():
            ip_data = self.df[self.df['source_ip'] == ip]

            ip_stats[ip] = {
                'total_requests': count,
                'log_types': ip_data['log_type'].value_counts().to_dict(),
                'severity_dist': ip_data['severity'].value_counts().to_dict(),
                'time_pattern': ip_data['hour'].value_counts().head(3).to_dict()
            }

        return ip_stats

    def plot_basic_stats(self, save_path: Optional[str] = None):
        """ê¸°ë³¸ í†µê³„ ì‹œê°í™”"""
        if len(self.df) == 0:
            print("ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        fig, axes = plt.subplots(2, 2, figsize=(15, 10))

        # 1. ì‹œê°„ëŒ€ë³„ ë¡œê·¸ ë¶„í¬
        hourly_counts = self.df['hour'].value_counts().sort_index()
        axes[0, 0].bar(hourly_counts.index, hourly_counts.values, color='skyblue')
        axes[0, 0].set_title('ì‹œê°„ëŒ€ë³„ ë¡œê·¸ ë¶„í¬', fontweight='bold')
        axes[0, 0].set_xlabel('ì‹œê°„')
        axes[0, 0].set_ylabel('ë¡œê·¸ ìˆ˜')

        # 2. ë¡œê·¸ íƒ€ì…ë³„ ë¶„í¬
        type_counts = self.df['log_type'].value_counts()
        axes[0, 1].pie(type_counts.values, labels=type_counts.index, autopct='%1.1f%%')
        axes[0, 1].set_title('ë¡œê·¸ íƒ€ì…ë³„ ë¶„í¬', fontweight='bold')

        # 3. ì‹¬ê°ë„ë³„ ë¶„í¬
        severity_counts = self.df['severity'].value_counts()
        axes[1, 0].bar(severity_counts.index, severity_counts.values,
                       color=['red', 'orange', 'yellow', 'green'])
        axes[1, 0].set_title('ì‹¬ê°ë„ë³„ ë¶„í¬', fontweight='bold')
        axes[1, 0].set_xlabel('ì‹¬ê°ë„')
        axes[1, 0].set_ylabel('ë¡œê·¸ ìˆ˜')

        # 4. ìƒìœ„ IP ë¶„í¬
        ip_counts = self.df['source_ip'].value_counts().head(10)
        axes[1, 1].barh(range(len(ip_counts)), ip_counts.values)
        axes[1, 1].set_yticks(range(len(ip_counts)))
        axes[1, 1].set_yticklabels(ip_counts.index)
        axes[1, 1].set_title('ìƒìœ„ 10ê°œ IP', fontweight='bold')
        axes[1, 1].set_xlabel('ìš”ì²­ ìˆ˜')

        plt.tight_layout()
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()

    def generate_basic_report(self) -> str:
        """ê¸°ë³¸ í†µê³„ ë¦¬í¬íŠ¸ ìƒì„±"""
        type_analysis = self.analyze_log_types()
        ip_analysis = self.analyze_source_ips()

        report = f"""
{'=' * 60}
ğŸ“Š ê¸°ë³¸ í†µê³„ ë¶„ì„ ë¦¬í¬íŠ¸ (Django ORM)
{'=' * 60}

{self.get_overview_text()}

{'=' * 60}

{self.get_time_analysis_text()}

{'=' * 60}
ğŸ“Š ë¡œê·¸ íƒ€ì…ë³„ ìƒì„¸ ë¶„ì„
{'=' * 60}
"""

        for log_type, analysis in type_analysis.items():
            report += f"\n[{log_type}]\n"
            report += f"â€¢ ê°œìˆ˜: {analysis['count']:,}ê°œ ({analysis['percentage']:.1f}%)\n"
            report += f"â€¢ ê³ ìœ  IP: {analysis['unique_ips']}ê°œ\n"
            if analysis['peak_hour']:
                report += f"â€¢ ìµœë‹¤ í™œë™ ì‹œê°„: {analysis['peak_hour']}ì‹œ\n"

        report += f"""

{'=' * 60}
ğŸŒ ìƒìœ„ IP ë¶„ì„
{'=' * 60}
"""

        for ip, stats in list(ip_analysis.items())[:5]:
            report += f"\n[{ip}]\n"
            report += f"â€¢ ì´ ìš”ì²­: {stats['total_requests']}ê°œ\n"
            main_type = max(stats['log_types'], key=stats['log_types'].get)
            report += f"â€¢ ì£¼ìš” ë¡œê·¸ íƒ€ì…: {main_type}\n"

        report += f"""

{'=' * 60}
ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Django ORM ê¸°ë°˜ ë¶„ì„
"""
        return report