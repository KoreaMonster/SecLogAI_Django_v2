#!/usr/bin/env python3
"""
Django ê¸°ë°˜ ì˜ˆì¸¡ ë¶„ì„ê¸°
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from django.apps import apps
import json

plt.rcParams['font.family'] = 'DejaVu Sans'
sns.set_style("whitegrid")


class PredictiveAnalyzer:
    def __init__(self):
        # Django ORM ì‚¬ìš©
        LogEntry = apps.get_model('logs', 'LogEntry')
        self.LogEntry = LogEntry
        self.df = None
        self._load_data()

    def _load_data(self):
        """Django ORMìœ¼ë¡œ ë°ì´í„° ë¡œë“œ"""
        entries = self.LogEntry.objects.all().values(
            'timestamp', 'log_type', 'source_ip', 'message', 'severity', 'metadata'
        )
        self.df = pd.DataFrame(entries)

        if len(self.df) > 0:
            self.df['timestamp'] = pd.to_datetime(self.df['timestamp'], errors='coerce')
            self.df = self.df.dropna(subset=['timestamp'])
            self.df['hour'] = self.df['timestamp'].dt.hour
            self.df['date'] = self.df['timestamp'].dt.date

    def get_numeric_metadata(self, data, field_name):
        """ë©”íƒ€ë°ì´í„°ì—ì„œ ìˆ«ì í•„ë“œ ì¶”ì¶œ"""

        def extract_numeric(metadata_str):
            try:
                if pd.isna(metadata_str):
                    return None
                metadata = json.loads(metadata_str)
                value = metadata.get(field_name)
                return float(value) if value is not None else None
            except:
                return None

        numeric_values = data['metadata'].apply(extract_numeric)
        return pd.to_numeric(numeric_values, errors='coerce').dropna()

    def get_prediction_overview_text(self) -> str:
        """ì˜ˆì¸¡ ë¶„ì„ ê°œìš”"""
        if len(self.df) == 0:
            return "ğŸ”® ë¶„ì„í•  ì˜ˆì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        total_logs = len(self.df)
        unique_ips = self.df['source_ip'].dropna().nunique()
        time_span = (self.df['timestamp'].max() - self.df['timestamp'].min()).days
        daily_avg = total_logs / max(time_span, 1)

        overview = f"""
ğŸ”® ì˜ˆì¸¡ ë¶„ì„ (Django ORM)
{'=' * 30}
â€¢ ì´ ë¡œê·¸ ìˆ˜: {total_logs:,}ê°œ
â€¢ ë¶„ì„ IP ìˆ˜: {unique_ips}ê°œ
â€¢ ë¶„ì„ ê¸°ê°„: {time_span}ì¼
â€¢ ì¼í‰ê·  ë¡œê·¸: {daily_avg:.1f}ê°œ
"""
        return overview

    def predict_traffic_volume(self) -> Tuple[Dict, str]:
        """íŠ¸ë˜í”½ ë³¼ë¥¨ ì˜ˆì¸¡"""
        if len(self.df) == 0:
            return {}, "íŠ¸ë˜í”½ ì˜ˆì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        # ì¼ë³„ íŠ¸ë˜í”½ íŒ¨í„´
        daily_volume = self.df.groupby('date').size()

        if len(daily_volume) < 3:
            return {}, "ì˜ˆì¸¡ì— ì¶©ë¶„í•œ ì¼ë³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        # ë‹¨ìˆœ ì„ í˜• íšŒê·€ë¡œ íŠ¸ë Œë“œ ì˜ˆì¸¡
        days = np.arange(len(daily_volume)).reshape(-1, 1)
        volumes = daily_volume.values

        model = LinearRegression()
        model.fit(days, volumes)

        # ë‹¤ìŒ 7ì¼ ì˜ˆì¸¡
        future_days = np.arange(len(daily_volume), len(daily_volume) + 7).reshape(-1, 1)
        predicted_volumes = model.predict(future_days)

        # í†µê³„ ê³„ì‚°
        current_avg = daily_volume.mean()
        predicted_avg = predicted_volumes.mean()
        trend = "ì¦ê°€" if predicted_avg > current_avg else "ê°ì†Œ"
        change_percent = ((predicted_avg - current_avg) / current_avg) * 100

        summary = f"""
ğŸ“ˆ íŠ¸ë˜í”½ ë³¼ë¥¨ ì˜ˆì¸¡
{'=' * 30}
â€¢ í˜„ì¬ ì¼í‰ê· : {current_avg:.1f}ê°œ
â€¢ ì˜ˆì¸¡ ì¼í‰ê· : {predicted_avg:.1f}ê°œ
â€¢ íŠ¸ë Œë“œ: {trend} ({change_percent:+.1f}%)
â€¢ ì˜ˆì¸¡ ê¸°ê°„: 7ì¼
"""

        return {
            'current_average': current_avg,
            'predicted_average': predicted_avg,
            'trend': trend,
            'change_percent': change_percent,
            'daily_volumes': daily_volume.to_dict(),
            'predictions': predicted_volumes.tolist()
        }, summary

    def extract_threat_features(self, ip_data):
        """IPë³„ ìœ„í˜‘ íŠ¹ì„± ì¶”ì¶œ"""
        features = []

        # ê¸°ë³¸ í†µê³„
        features.append(len(ip_data))  # ì´ ìš”ì²­ ìˆ˜
        features.append(len(ip_data['log_type'].unique()))  # ë¡œê·¸ íƒ€ì… ë‹¤ì–‘ì„±
        features.append(len(ip_data[ip_data['severity'] == 'high']))  # ê³ ìœ„í—˜ ì´ë²¤íŠ¸ ìˆ˜

        # ì‹œê°„ íŒ¨í„´
        features.append(len(ip_data['hour'].unique()))  # í™œë™ ì‹œê°„ëŒ€ ìˆ˜

        # ì›¹ ê´€ë ¨ íŠ¹ì„± (apache ë¡œê·¸ê°€ ìˆëŠ” ê²½ìš°)
        apache_data = ip_data[ip_data['log_type'] == 'apache']
        if len(apache_data) > 0:
            status_codes = self.get_numeric_metadata(apache_data, 'status_code')
            if len(status_codes) > 0:
                features.append(len(status_codes[status_codes >= 400]))  # 4xx, 5xx ì—ëŸ¬
                features.append(status_codes.mean())  # í‰ê·  ìƒíƒœ ì½”ë“œ
            else:
                features.extend([0, 200])  # ê¸°ë³¸ê°’
        else:
            features.extend([0, 200])  # apache ë¡œê·¸ ì—†ìŒ

        return features

    def predict_security_threats(self) -> Tuple[Dict, str]:
        """ë³´ì•ˆ ìœ„í˜‘ ì˜ˆì¸¡"""
        if len(self.df) == 0:
            return {}, "ë³´ì•ˆ ìœ„í˜‘ ì˜ˆì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        # ë³´ì•ˆ ê´€ë ¨ íŠ¹ì„± ì¶”ì¶œ
        threat_features = []
        threat_ips = []

        for ip in self.df['source_ip'].dropna().unique():
            ip_data = self.df[self.df['source_ip'] == ip]
            features = self.extract_threat_features(ip_data)
            threat_features.append(features)
            threat_ips.append(ip)

        if len(threat_features) < 5:
            return {}, "ìœ„í˜‘ ì˜ˆì¸¡ì— ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        # íŠ¹ì„± ê¸¸ì´ í†µì¼
        max_features = max(len(features) for features in threat_features)
        normalized_features = []
        for features in threat_features:
            while len(features) < max_features:
                features.append(0)
            normalized_features.append(features)

        # Isolation Forestë¡œ ì´ìƒ IP íƒì§€
        try:
            scaler = StandardScaler()
            features_scaled = scaler.fit_transform(normalized_features)

            isolation_forest = IsolationForest(contamination=0.1, random_state=42)
            anomaly_scores = isolation_forest.fit_predict(features_scaled)

            threat_ips_list = [threat_ips[i] for i, score in enumerate(anomaly_scores) if score == -1]

            # ìœ„í˜‘ IPë“¤ì˜ ìƒì„¸ ë¶„ì„
            threat_analysis = {}
            for ip in threat_ips_list:
                ip_data = self.df[self.df['source_ip'] == ip]

                analysis = {
                    'total_requests': len(ip_data),
                    'high_severity_events': len(ip_data[ip_data['severity'] == 'high']),
                    'main_log_types': ip_data['log_type'].value_counts().to_dict(),
                    'time_pattern': ip_data['hour'].value_counts().head(3).to_dict()
                }

                # ì›¹ ê³µê²© íŒ¨í„´
                apache_data = ip_data[ip_data['log_type'] == 'apache']
                if len(apache_data) > 0:
                    status_codes = self.get_numeric_metadata(apache_data, 'status_code')
                    if len(status_codes) > 0:
                        analysis['web_errors'] = len(status_codes[status_codes >= 400])

                threat_analysis[ip] = analysis

        except Exception as e:
            return {}, f"ìœ„í˜‘ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

        summary = f"""
ğŸš¨ ë³´ì•ˆ ìœ„í˜‘ ì˜ˆì¸¡
{'=' * 30}
â€¢ ë¶„ì„ëœ IP ìˆ˜: {len(threat_ips)}ê°œ
â€¢ ìœ„í—˜ IP ìˆ˜: {len(threat_ips_list)}ê°œ
â€¢ ìœ„í—˜ë„ ì„ê³„ê°’: 10%
"""

        if threat_ips_list:
            summary += f"\nâ€¢ ì£¼ìš” ìœ„í—˜ IP: {', '.join(threat_ips_list[:5])}"

        return {
            'threat_ips': threat_ips_list,
            'total_analyzed': len(threat_ips),
            'threat_analysis': threat_analysis
        }, summary

    def predict_system_load(self) -> Tuple[Dict, str]:
        """ì‹œìŠ¤í…œ ë¶€í•˜ ì˜ˆì¸¡"""
        if len(self.df) == 0:
            return {}, "ì‹œìŠ¤í…œ ë¶€í•˜ ì˜ˆì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        # ì¼ë³„ ë¡œê·¸ ë³¼ë¥¨
        daily_volume = self.df.groupby('date').size()

        if len(daily_volume) < 3:
            return {}, "ë¶€í•˜ ì˜ˆì¸¡ì— ì¶©ë¶„í•œ ì¼ë³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        # í†µê³„ì  ë¶„ì„
        volume_mean = daily_volume.mean()
        volume_std = daily_volume.std()

        # ë¶€í•˜ ìˆ˜ì¤€ ë¶„ë¥˜
        high_load_days = len(daily_volume[daily_volume > volume_mean + volume_std])
        normal_load_days = len(daily_volume[abs(daily_volume - volume_mean) <= volume_std])
        low_load_days = len(daily_volume[daily_volume < volume_mean - volume_std])

        # ìµœê·¼ íŠ¸ë Œë“œ (ìµœê·¼ 3ì¼)
        recent_volumes = daily_volume.tail(3)
        recent_avg = recent_volumes.mean()

        if recent_avg > volume_mean + volume_std:
            load_prediction = "ë†’ì€ ë¶€í•˜"
        elif recent_avg < volume_mean - volume_std:
            load_prediction = "ë‚®ì€ ë¶€í•˜"
        else:
            load_prediction = "ì •ìƒ ë¶€í•˜"

        summary = f"""
âš¡ ì‹œìŠ¤í…œ ë¶€í•˜ ì˜ˆì¸¡
{'=' * 30}
â€¢ í‰ê·  ì¼ì¼ ë¶€í•˜: {volume_mean:.1f}ê°œ
â€¢ ìµœê·¼ 3ì¼ í‰ê· : {recent_avg:.1f}ê°œ
â€¢ ì˜ˆìƒ ë¶€í•˜ ìˆ˜ì¤€: {load_prediction}
â€¢ ê³ ë¶€í•˜ ë°œìƒì¼: {high_load_days}ì¼
"""

        return {
            'average_load': volume_mean,
            'recent_average': recent_avg,
            'load_prediction': load_prediction,
            'high_load_days': high_load_days,
            'normal_load_days': normal_load_days,
            'low_load_days': low_load_days
        }, summary

    def predict_peak_times(self) -> Tuple[Dict, str]:
        """í”¼í¬ ì‹œê°„ ì˜ˆì¸¡"""
        if len(self.df) == 0:
            return {}, "í”¼í¬ ì‹œê°„ ì˜ˆì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        # ì‹œê°„ë³„ í™œë™ íŒ¨í„´
        hourly_activity = self.df.groupby('hour').size()

        # í”¼í¬ ì‹œê°„ ì‹ë³„
        activity_mean = hourly_activity.mean()
        peak_hours = hourly_activity[hourly_activity > activity_mean * 1.5].index.tolist()

        # ìš”ì¼ë³„ íŒ¨í„´ (ê°€ëŠ¥í•œ ê²½ìš°)
        self.df['weekday'] = self.df['timestamp'].dt.dayofweek
        weekday_activity = self.df.groupby('weekday').size()
        busiest_weekday = weekday_activity.idxmax()
        weekday_names = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']

        summary = f"""
â° í”¼í¬ ì‹œê°„ ì˜ˆì¸¡
{'=' * 30}
â€¢ í”¼í¬ ì‹œê°„ëŒ€: {', '.join(map(str, peak_hours))}ì‹œ
â€¢ ì‹œê°„ë‹¹ í‰ê· : {activity_mean:.1f}ê°œ
â€¢ ìµœë‹¤ í™œë™ ìš”ì¼: {weekday_names[busiest_weekday]}ìš”ì¼
"""

        return {
            'peak_hours': peak_hours,
            'hourly_average': activity_mean,
            'busiest_weekday': busiest_weekday,
            'hourly_distribution': hourly_activity.to_dict()
        }, summary

    def plot_predictions(self, save_path: Optional[str] = None):
        """ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”"""
        if len(self.df) == 0:
            print("ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        fig, axes = plt.subplots(2, 2, figsize=(15, 10))

        # 1. íŠ¸ë˜í”½ ë³¼ë¥¨ íŠ¸ë Œë“œì™€ ì˜ˆì¸¡
        daily_volume = self.df.groupby('date').size()
        if len(daily_volume) >= 3:
            axes[0, 0].plot(daily_volume.index, daily_volume.values, marker='o', label='ì‹¤ì œ ë°ì´í„°')

            # íŠ¸ë Œë“œ ë¼ì¸
            days = np.arange(len(daily_volume))
            z = np.polyfit(days, daily_volume.values, 1)
            p = np.poly1d(z)
            axes[0, 0].plot(daily_volume.index, p(days), "--", alpha=0.8, label='íŠ¸ë Œë“œ')

            axes[0, 0].set_title('ì¼ë³„ íŠ¸ë˜í”½ ë³¼ë¥¨ íŠ¸ë Œë“œ', fontweight='bold')
            axes[0, 0].set_xlabel('ë‚ ì§œ')
            axes[0, 0].set_ylabel('ë¡œê·¸ ìˆ˜')
            axes[0, 0].legend()
            axes[0, 0].tick_params(axis='x', rotation=45)
        else:
            axes[0, 0].text(0.5, 0.5, 'íŠ¸ë Œë“œ ë°ì´í„° ë¶€ì¡±', transform=axes[0, 0].transAxes,
                            ha='center', va='center', fontsize=12)
            axes[0, 0].set_title('ì¼ë³„ íŠ¸ë˜í”½ ë³¼ë¥¨ íŠ¸ë Œë“œ', fontweight='bold')

        # 2. ì‹œìŠ¤í…œ ë¶€í•˜ ë ˆë²¨ ë¶„í¬
        daily_volume = self.df.groupby('date').size()
        if len(daily_volume) >= 3:
            volume_mean = daily_volume.mean()
            volume_std = daily_volume.std()

            high_load = len(daily_volume[daily_volume > volume_mean + volume_std])
            normal_load = len(daily_volume[abs(daily_volume - volume_mean) <= volume_std])
            low_load = len(daily_volume[daily_volume < volume_mean - volume_std])

            axes[0, 1].bar(['ë‚®ì€ ë¶€í•˜', 'ì •ìƒ ë¶€í•˜', 'ë†’ì€ ë¶€í•˜'],
                           [low_load, normal_load, high_load],
                           color=['green', 'yellow', 'red'])
            axes[0, 1].set_title('ì‹œìŠ¤í…œ ë¶€í•˜ ìˆ˜ì¤€ ë¶„í¬', fontweight='bold')
            axes[0, 1].set_ylabel('ì¼ìˆ˜')
        else:
            axes[0, 1].text(0.5, 0.5, 'ë¶€í•˜ ë°ì´í„° ë¶€ì¡±', transform=axes[0, 1].transAxes,
                            ha='center', va='center', fontsize=12)
            axes[0, 1].set_title('ì‹œìŠ¤í…œ ë¶€í•˜ ìˆ˜ì¤€ ë¶„í¬', fontweight='bold')

        # 3. ì‹œê°„ë³„ í™œë™ íŒ¨í„´ê³¼ í”¼í¬ ì˜ˆì¸¡
        hourly_activity = self.df.groupby('hour').size()
        activity_mean = hourly_activity.mean()

        bars = axes[1, 0].bar(hourly_activity.index, hourly_activity.values, alpha=0.7)
        axes[1, 0].axhline(y=activity_mean * 1.5, color='red', linestyle='--',
                           label='í”¼í¬ ì„ê³„ê°’')

        # í”¼í¬ ì‹œê°„ ê°•ì¡°
        peak_hours = hourly_activity[hourly_activity > activity_mean * 1.5].index
        for hour in peak_hours:
            if hour in hourly_activity.index:
                idx = list(hourly_activity.index).index(hour)
                bars[idx].set_color('red')

        axes[1, 0].set_title('ì‹œê°„ë³„ í™œë™ íŒ¨í„´ ë° í”¼í¬ ì˜ˆì¸¡', fontweight='bold')
        axes[1, 0].set_xlabel('ì‹œê°„')
        axes[1, 0].set_ylabel('ë¡œê·¸ ìˆ˜')
        axes[1, 0].legend()

        # 4. ìœ„í—˜ IP ì˜ˆì¸¡ ê²°ê³¼
        threat_pred, _ = self.predict_security_threats()
        if threat_pred and threat_pred.get('total_analyzed', 0) > 0:
            threat_count = len(threat_pred.get('threat_ips', []))
            safe_count = threat_pred.get('total_analyzed', 0) - threat_count

            axes[1, 1].pie([safe_count, threat_count],
                           labels=['ì•ˆì „ IP', 'ìœ„í—˜ IP'],
                           colors=['lightgreen', 'red'],
                           autopct='%1.1f%%')
            axes[1, 1].set_title('IP ìœ„í—˜ë„ ì˜ˆì¸¡', fontweight='bold')
        else:
            axes[1, 1].text(0.5, 0.5, 'ìœ„í—˜ë„ ì˜ˆì¸¡ ë°ì´í„° ë¶€ì¡±',
                            transform=axes[1, 1].transAxes, ha='center', va='center')
            axes[1, 1].set_title('IP ìœ„í—˜ë„ ì˜ˆì¸¡', fontweight='bold')

        plt.tight_layout()
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()

    def generate_prediction_report(self) -> str:
        """ì˜ˆì¸¡ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        traffic_analysis, traffic_summary = self.predict_traffic_volume()
        threat_analysis, threat_summary = self.predict_security_threats()
        load_analysis, load_summary = self.predict_system_load()
        peak_analysis, peak_summary = self.predict_peak_times()

        report = f"""
{'=' * 60}
ğŸ”® ì˜ˆì¸¡ ë¶„ì„ ë¦¬í¬íŠ¸ (Django ORM)
{'=' * 60}

{self.get_prediction_overview_text()}

{'=' * 60}
{traffic_summary}
{'=' * 60}
"""

        if traffic_analysis:
            report += f"ìƒì„¸ íŠ¸ë˜í”½ ì˜ˆì¸¡:\n"
            report += f"â€¢ í˜„ì¬ í‰ê· : {traffic_analysis['current_average']:.1f}ê°œ/ì¼\n"
            report += f"â€¢ ì˜ˆì¸¡ í‰ê· : {traffic_analysis['predicted_average']:.1f}ê°œ/ì¼\n"
            report += f"â€¢ ë³€í™”ìœ¨: {traffic_analysis['change_percent']:+.1f}%\n"

        report += f"""

{'=' * 60}
{threat_summary}
{'=' * 60}
"""

        threat_ips = threat_analysis.get('threat_ips', [])
        for i, ip in enumerate(threat_ips[:5], 1):
            threat_info = threat_analysis.get('threat_analysis', {}).get(ip, {})
            report += f"\n{i}. {ip}\n"
            report += f"   â€¢ ì´ ìš”ì²­: {threat_info.get('total_requests', 0)}ê°œ\n"
            report += f"   â€¢ ê³ ìœ„í—˜ ì´ë²¤íŠ¸: {threat_info.get('high_severity_events', 0)}ê°œ\n"

        report += f"""

{'=' * 60}
{load_summary}
{'=' * 60}
{peak_summary}
{'=' * 60}
ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Django ORM ê¸°ë°˜ ì˜ˆì¸¡ ë¶„ì„
"""
        return report